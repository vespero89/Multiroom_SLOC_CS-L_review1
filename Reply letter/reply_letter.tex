\documentclass[11pt, technote, letterpaper, oneside, onecolumn]{IEEEtran}
\usepackage{amssymb,amsmath}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{tabularx}
\usepackage{array}
\usepackage{verbatim}
\usepackage{color}
\usepackage{url}
\usepackage{algorithmicx}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{stmaryrd}
\usepackage{amsfonts}
\usepackage{textcomp}
\usepackage{tikz}
\usepackage{nth}
\usepackage{multirow}
\usepackage{mathtools}

\begin{document}


% Introduce a new counter for counting the nodes needed for circling
\newcounter{nodecount}
% Command for making a new node and naming it according to the nodecount counter
\newcommand\tabnode[1]{\addtocounter{nodecount}{1}\tikz \node (\arabic{nodecount}) {#1};}

\textbf{RESPONSE TO REVIEWERS}


\vspace{+2\baselineskip}

\noindent Dear Editor,

\vspace{+0.1\baselineskip}

first of all we would like to thank the reviewers for contributing with their insightful comments. We have revised the manuscript according to them, and detailed replies are listed below to identify the applied changes.  We really appreciate the review work which helped us to improve the scientific impact of the paper and its presentation quality. 
\vspace{+0.5\baselineskip}

\noindent Best regards,

\vspace{+0.1\baselineskip}

The Authors

\vspace{+3\baselineskip}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage

\section{Answers to reviewer 1}\label{sec:rev1}
\begin{itemize}
\item Given that a map of the environment is available, it would be interesting to see the performance of a ray-tracing style algorithm. It should be possible to find the intersection of all the paths given by the peaks in each microphone pair GCC-PHAT output. If it is not feasible to carry out this experiment, I would suggest a dicussion of this kind of method and refer to literature.\\
\textbf{Reply}:

\item Assuming that the microphones are calibrated, a simple way of determining speaker position is to used the signal strength. This would also be valuable to include in a discussion.\\
\textbf{Reply}:

\item It would be nice to have the problem more clearly defined earlier in the paper, e.g., single- or multi-speaker localization, moving or stationary, are signals from all rooms used simultaneously, are there more than one microphone pair etc.\\
\textbf{Reply}:

\item What are the outputs of the algorithms? Coordinates? How to make sure, that only valid coordinates are chosen?\\
\textbf{Reply}:

\item Did the authors experiment with the frame ? 480ms seems quite high to me and seems to violate the assumption of the aqcuired signal to be almost stationary within a frame. In my experience 64-128 is more appropriate.\\
\textbf{Reply}:

\item It would also be interesting to discuss the applications of such systems and how it might impact the solution. For some applications it is not necessary to have a frame-level output.\\
\textbf{Reply}:

\item It would be nice to have a motivation for introducing convolutional networks. Why might it be expected to improve performance? I know that it can probably only be speculations, but as it is now, it appears a bit like trial-and-error.\\
\textbf{Reply}:

\item When comparing the two architectures, where one considers all signals from all (both) rooms vs only signals from the room with the source, how is the room with the source determined, i.e., how do you know which rooms contains the source/speaker?\\
\textbf{Reply}:

\item Evaluation: It would be very interesting to have a plot of all the source/target locations on a map, to see their distribution.\\
\textbf{Reply}:

\item Evaluation: Does the baseline methods, CSP and SRP, use any smoothing or temporal context or are they simply evaluated frame by frame? Based on my experience a simple histogram technique computed over a few seconds can improve robustness quite a lot.\\
\textbf{Reply}:

\item Evaluation: How was the 500mm threshold determined?\\
\textbf{Reply}:

\item Evaluation: What was the number for N\_TOT?\\
\textbf{Reply}:

\item Evaluation: Line 358: The explanation about the boxplot could be expanded to explain things better\\
\textbf{Reply}:

\item Evaluation: Fig. 8b (Kitchen), What happens at C=17? This seems very strange.\\
\textbf{Reply}:

\item Line 395: From what figure/numbers can I deduce this? It seems unclear, and what is temporal resolution in this case? Equal to C?\\
\textbf{Reply}:

\item The best performance is found when context corresponding to 8.5s is considered, which in my opinion is quite a lot for some applications but for others it is acceptable. This should be addressed.\\
\textbf{Reply}:

\item Evaluation: In the case of real environment (Tab. 6) SRP performs equally well with the proposed methods when not considering temporal context. Could a simple extension of the SRP with maybe a histogram approach be considered? I would expect it to yield an improvement.\\
\textbf{Reply}:

\item line 188: How are the frames containing speech found?\\
\textbf{Reply}:

\item Bullet 2 on line 321: I do not completely understand what is going on here, and it is quite difficult to understand from the text. Please elaborate and motivate it.\\
\textbf{Reply}:

\item Conclusion: To me, the conclusion is way too optimistic and biased. Two main points to challenge are:\\
 1: It is true, that no tuning of parameters are needed once the network is ALREADY trained, but based on the experiments in this paper it is obvious that some tuning has been done to find the best performance. Furthermore, what are all these parameters in state-of-the art methods which need tuning? I would like to have a concrete example.\\
 2: The authors implicitly claim that this performance of the architectures can be generalised to all rooms when trained, however this is not demonstrated properly. An interesting experiment would be to choose test the same architecture on a set of two new rooms. This would at least give a hint to how it generalises.\\
 \textbf{Reply}:

\item It seems like the authors put very little cost to the process of training such a system. In the current system, I believe, 64 minutes are used for training, at least for the simulated scenario. How is this expected to be handled in a commercial product, if it has to be trained specifically for that particular environment?\\
\textbf{Reply}:

\item Minor comments: Line 454: ".. by means of close in time frames". I understand, but it is not proper English.\\
\textbf{Reply}:
\end{itemize}

\newpage
\section{Answers to reviewer 2}\label{sec:rev2}
\begin{itemize}
\item In page 7, line 134. "the coordinates $(\chi,\phi)$, i.e.," It is unclear what $\chi$ and $\phi$ represent. Please define the two symbols clearly and give their units. It seems very important due to that Eq. (15) defines the RMSE, and the unit of RMSE is millimeter (mm). $\phi$ is often denoted as angle.\\
\textbf{Reply}:
\item  In page 9, "for each considered microphone pair the CSPCM is computed with a frame and a hop respectively equal to 480 ms and 160 ms." I doubt about the frame and the hop here, it is not common to compute the CSPCM using a half-second long data segment. There are several reasons for this. First, the speech is only quasi-stationary. Second, it is unnecessary to use so long data segment to obtain the GCC-PHAT pattern since the maximum delay is only 24 samples as pointed out in Eq. (3). Third, the tracking capability will reduce dramatically when using so long data segment.\\
\textbf{Reply}:
\item  It is unclear why 500mm is chosen as a threshold. Why not other values, like 1000mm?\\
\textbf{Reply}:
\item  GCC-PHAT can also be applied to speaker localization directly, why not compare the proposed algorithm with the GCC-PHAT-based localization. \\
\textbf{Reply}:
\item  For the reverberant and noisy environments, it is common to suppress the noise and the reverberant components beforehand to improve the localization accuracy. Moreover, as we know, if we properly choose some time-frequency bins that have high CDR or SNR values, the localization accuracy can also be improved dramatically.\\
\textbf{Reply}:

\item  Please compare the computational complexity of these algorithms.\\
\textbf{Reply}:

\end{itemize}

\end{document}
